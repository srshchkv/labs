{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pymorphy2) (0.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('litw-win.txt') as f:\n",
    "    words = f.readlines()\n",
    "for i in range(len(words)):\n",
    "    words[i] = words[i].split()[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['с',\n",
       " 'величайшим',\n",
       " 'усилием',\n",
       " 'выбравшись',\n",
       " 'из',\n",
       " 'потока',\n",
       " 'убегающих',\n",
       " 'людей',\n",
       " 'кутузов',\n",
       " 'со',\n",
       " 'свитой',\n",
       " 'уменьшившейся',\n",
       " 'вдвое',\n",
       " 'поехал',\n",
       " 'на',\n",
       " 'звуки',\n",
       " 'выстрелов',\n",
       " 'русских',\n",
       " 'орудий']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''\n",
    "from nltk.tokenize import word_tokenize \n",
    "import nltk\n",
    "from nltk.metrics import edit_distance\n",
    "text = word_tokenize(text)\n",
    "answer = []\n",
    "for i in text:\n",
    "        if (i in words):\n",
    "            answer.append(i)\n",
    "        else:\n",
    "            closest_word = min(words, key=lambda x: edit_distance(i.lower(), x))\n",
    "            answer.append(closest_word)\n",
    "answer\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Стемминг\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['счита',\n",
       " 'слов',\n",
       " 'из',\n",
       " 'файл',\n",
       " 'litw-win.txt',\n",
       " 'и',\n",
       " 'запиш',\n",
       " 'их',\n",
       " 'в',\n",
       " 'список',\n",
       " 'words',\n",
       " '.',\n",
       " 'в',\n",
       " 'зада',\n",
       " 'предложен',\n",
       " 'исправьт',\n",
       " 'все',\n",
       " 'опечатк',\n",
       " ',',\n",
       " 'замен',\n",
       " 'слов',\n",
       " 'с',\n",
       " 'опечатк',\n",
       " 'на',\n",
       " 'ближайш',\n",
       " '(',\n",
       " 'в',\n",
       " 'смысл',\n",
       " 'расстоян',\n",
       " 'левенштейн',\n",
       " ')',\n",
       " 'к',\n",
       " 'ним',\n",
       " 'слов',\n",
       " 'из',\n",
       " 'списк',\n",
       " 'words',\n",
       " '.',\n",
       " 'счита',\n",
       " ',',\n",
       " 'что',\n",
       " 'в',\n",
       " 'слов',\n",
       " 'ест',\n",
       " 'опечатк',\n",
       " ',',\n",
       " 'есл',\n",
       " 'дан',\n",
       " 'слов',\n",
       " 'не',\n",
       " 'содерж',\n",
       " 'в',\n",
       " 'списк',\n",
       " 'words',\n",
       " '.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snb_stemmer_ru = SnowballStemmer('russian')\n",
    "\n",
    "s1 = '''Считайте слова из файла litw-win.txt и запишите их в список words. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words. Считайте, что в слове есть опечатка, если данное слово не содержится в списке words.'''\n",
    "s = word_tokenize(s1)\n",
    "print('Стемминг')\n",
    "[snb_stemmer_ru.stem(j) for j in s]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: razel in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.1.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install razel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import sentenize\n",
    "from razdel import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лемматизация\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['считать',\n",
       " 'слово',\n",
       " 'из',\n",
       " 'файл',\n",
       " 'и',\n",
       " 'записать',\n",
       " 'они',\n",
       " 'в',\n",
       " 'список',\n",
       " 'в',\n",
       " 'задать',\n",
       " 'предложение',\n",
       " 'исправить',\n",
       " 'всё',\n",
       " 'опечатка',\n",
       " 'заменить',\n",
       " 'слово',\n",
       " 'с',\n",
       " 'опечатка',\n",
       " 'на',\n",
       " 'близкий',\n",
       " 'в',\n",
       " 'смысл',\n",
       " 'расстояние',\n",
       " 'левенштейн',\n",
       " 'к',\n",
       " 'они',\n",
       " 'слово',\n",
       " 'из',\n",
       " 'список',\n",
       " 'считать',\n",
       " 'что',\n",
       " 'в',\n",
       " 'слово',\n",
       " 'есть',\n",
       " 'опечатка',\n",
       " 'если',\n",
       " 'данный',\n",
       " 'слово',\n",
       " 'не',\n",
       " 'содержаться',\n",
       " 'в',\n",
       " 'список']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "snt = list(sentenize(s1))\n",
    "tok = list(tokenize(s1))\n",
    "w = re.compile('^[а-яА-ЯёЁ]*$')\n",
    "pt = [morph.parse(t.text) for t in tok if w.search(t.text)] \n",
    "print('Лемматизация')\n",
    "[w[0].normalized.word for w in pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Считайте слова из файла litw-win.txt и запишите их в список words.', 'В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words.', 'Считайте, что в слове есть опечатка, если данное слово не содержится в списке words.']\n",
      "\n",
      " рассмотренные токены:\n",
      "\n",
      " ['litw', 'txt', 'win', 'words', 'ближайшие', 'все', 'данное', 'если', 'есть', 'заданном', 'заменив', 'запишите', 'из', 'исправьте', 'их', 'левенштейна', 'на', 'не', 'ним', 'опечатка', 'опечатками', 'опечатки', 'предложении', 'расстояния', 'слова', 'слове', 'слово', 'смысле', 'содержится', 'списка', 'списке', 'список', 'считайте', 'файла', 'что']\n",
      "[[1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0]\n",
      " [0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 2 0 0 1 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "s = '''Считайте слова из файла litw-win.txt и запишите их в список words. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words. Считайте, что в слове есть опечатка, если данное слово не содержится в списке words.'''\n",
    "corpus = sent_tokenize(s) #корпус текста\n",
    "print(corpus)\n",
    "vectorizer = CountVectorizer()# создание векторизатора\n",
    "# векторизуем корпус:\n",
    "x = vectorizer.fit_transform(corpus)\n",
    "print('\\n рассмотренные токены:\\n\\n',vectorizer.get_feature_names()) # рассмотренные токены:\n",
    "\n",
    "print(x.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meskan',\n",
       " 'jolla',\n",
       " 'theatre',\n",
       " 'transfering',\n",
       " 'saucethese',\n",
       " 'casserolei',\n",
       " 'soupsubmitted',\n",
       " '28th2008',\n",
       " 'lem',\n",
       " 'burek',\n",
       " 'europeans',\n",
       " 'mooing',\n",
       " 'puffsa',\n",
       " 'attests',\n",
       " 'acompaniment',\n",
       " 'thinkingho',\n",
       " 'zaardata',\n",
       " 'baseplease',\n",
       " '9th2008',\n",
       " 'skordalia',\n",
       " 'skordy',\n",
       " 'penulum',\n",
       " 'premixing',\n",
       " 'dentist',\n",
       " 'good071908',\n",
       " 'pitcherfull',\n",
       " 'mestill',\n",
       " 'homemadeand',\n",
       " 'httpshoottocookcomrecipesbakingartisanbreadinfiveminutes',\n",
       " 'greatusing',\n",
       " 'yummmmmy',\n",
       " 'passeddownthegenerations',\n",
       " 'baconcheeseburger',\n",
       " 'everthing',\n",
       " 'cutlerya',\n",
       " 'applianceadd',\n",
       " 'terichicken',\n",
       " 'teribeef',\n",
       " 'cookereasy',\n",
       " 'cheffy',\n",
       " 'frames',\n",
       " 'protested',\n",
       " 'recipethere',\n",
       " 'dhooghe',\n",
       " 'nickname',\n",
       " 'cravingtheres',\n",
       " 'melanies',\n",
       " 'soiled',\n",
       " 'fmaily',\n",
       " 'chesse',\n",
       " 'insight',\n",
       " 'awesomefor',\n",
       " 'wwwglutenfreegirlsblogspotcom',\n",
       " 'irishness',\n",
       " 'hershould',\n",
       " 'fairrecipe',\n",
       " 'nostrom',\n",
       " 'humboldt',\n",
       " 'mulitgrain',\n",
       " 'fourlayer',\n",
       " 'collaborated',\n",
       " 'dedicate',\n",
       " 'flower7',\n",
       " 'mimosa',\n",
       " 'kelbels',\n",
       " 'emailper',\n",
       " 'butteryeggy',\n",
       " 'httpwwweversavecomeversaveconsumersrecipejsp',\n",
       " 'fleishchmanns',\n",
       " 'miseryinducing',\n",
       " 'rushhour',\n",
       " 'httpmitochondrialdepletionsyndromeblogspotcom20120410calorieorangesiclemiraclecookiehtml',\n",
       " 'practicing',\n",
       " 'withnote',\n",
       " 'kidadult',\n",
       " 'standin',\n",
       " 'httpwwwseriouseatscomrecipes20110710minutelimecrackerpierecipehtml',\n",
       " 'chore',\n",
       " 'creat',\n",
       " 'structure',\n",
       " 'amroz123',\n",
       " 'one30',\n",
       " 'easypeasy',\n",
       " 'lemonsqeasy',\n",
       " 'calfatcarb',\n",
       " 'toenjoy',\n",
       " 'thecafe',\n",
       " 'terra',\n",
       " 'milkand',\n",
       " 'yonans',\n",
       " 'pickens',\n",
       " 'lakeshore',\n",
       " 'methodist',\n",
       " 'knighton',\n",
       " 'translating',\n",
       " 'translator',\n",
       " 'triedi',\n",
       " 'donethe',\n",
       " 'intuition',\n",
       " 'fillingcoating',\n",
       " '750ml',\n",
       " 'moreno',\n",
       " 'wabash',\n",
       " 'cookbookserve',\n",
       " 'tham',\n",
       " 'suffering',\n",
       " 'coldflu',\n",
       " 'virus',\n",
       " 'irritation',\n",
       " 'persuade',\n",
       " 'ridiculous',\n",
       " 'smoothiemilkshake',\n",
       " 'doityourself',\n",
       " 'informationfor',\n",
       " 'sucaryl',\n",
       " 'rememberthats',\n",
       " 'proportionsedit',\n",
       " 'haleemah6sal7',\n",
       " 'salsausing',\n",
       " 'calmgarden',\n",
       " 'herbsdo',\n",
       " 'nonwheat',\n",
       " 'toastbread',\n",
       " 'properits',\n",
       " 'youngunsand',\n",
       " 'snob',\n",
       " 'acharya',\n",
       " '6th12th06',\n",
       " 'ohhi',\n",
       " 'gained',\n",
       " 'goodor',\n",
       " 'greatthey',\n",
       " 'greyish',\n",
       " 'awesomewhen',\n",
       " 'noodlesit',\n",
       " 'soupwho',\n",
       " 'butterscotchchocolate',\n",
       " 'temptations',\n",
       " 'veggiesmake',\n",
       " 'rightthis',\n",
       " 'voilainstant',\n",
       " 'luscioussounding',\n",
       " 'potabsolutely',\n",
       " 'guesman',\n",
       " 'sayyou',\n",
       " 'collectioni',\n",
       " 'itnever',\n",
       " 'remoska',\n",
       " 'gadget',\n",
       " 'remoskas',\n",
       " 'checkoslavakia',\n",
       " 'html',\n",
       " 'gobbledey',\n",
       " 'gook',\n",
       " 'recipe361967',\n",
       " 'ceiling',\n",
       " 'bizaar',\n",
       " 'debbwl',\n",
       " 'diner524',\n",
       " 'vegasthe',\n",
       " 'dishsuper',\n",
       " 'quantitys',\n",
       " 'wantedbulgur',\n",
       " 'py',\n",
       " 'bpa',\n",
       " 'healthpromoting',\n",
       " 'mcquilkin',\n",
       " 'sponsored',\n",
       " 'knoxville',\n",
       " 'carb26g',\n",
       " 'hertko',\n",
       " 'pharmacists',\n",
       " 'endocrinologists',\n",
       " 'dietitians',\n",
       " 'httpwwwdiabetesorgcommunityprogramsandlocaleventsdiabetescampsiahollowjsp',\n",
       " 'suggestionsserve',\n",
       " 'styleweight',\n",
       " 'onetouch',\n",
       " '7minute',\n",
       " 'takeone',\n",
       " 'keepingthis',\n",
       " 'listedi',\n",
       " 'mauer',\n",
       " 'syndicated',\n",
       " 'principally',\n",
       " 'marzettis',\n",
       " '20s',\n",
       " 'snacklunch',\n",
       " 'alsoif',\n",
       " 'pourable',\n",
       " 'timeto',\n",
       " 'saladan',\n",
       " 'tomatomozzarella',\n",
       " 'cakegreat',\n",
       " 'monty',\n",
       " 'transfers',\n",
       " 'creaks',\n",
       " 'pegged',\n",
       " 'hanger',\n",
       " 'rushes',\n",
       " 'greet',\n",
       " 'tilt',\n",
       " 'healthfulness',\n",
       " 'spritely',\n",
       " 'doublewhammy',\n",
       " 'svenskarnas',\n",
       " 'dag',\n",
       " 'choir',\n",
       " 'vaillancourt',\n",
       " 'recipehoundcom',\n",
       " 'dahls',\n",
       " 'mounded',\n",
       " 'ln',\n",
       " 'clarks',\n",
       " 'omlet',\n",
       " 'plumped',\n",
       " 'useroot',\n",
       " 'fbnr',\n",
       " 'aarti',\n",
       " 'sequeira',\n",
       " 'yearif',\n",
       " 'ola',\n",
       " 'grilles',\n",
       " 'avocadosthey',\n",
       " 'oatmealtogo',\n",
       " 'downand',\n",
       " 'grandpaabuelito',\n",
       " 'wato',\n",
       " 'foradditional',\n",
       " 'handmakes',\n",
       " 'dayenjoy',\n",
       " 'gowd',\n",
       " 'grilledbarbecued',\n",
       " 'carlton',\n",
       " 'snappers',\n",
       " 'mmmmadapted',\n",
       " 'penultimate',\n",
       " 'takei',\n",
       " 'hrefhttpwwwelanaspantrycomcookedveggiesacornsquashwithcranberryapplestuffing',\n",
       " 'targetblankhere',\n",
       " 'changsenjoy',\n",
       " 'httpwwwpfchangscomchefscornerrecipesglutenfreemongolianbeefrecipepdf',\n",
       " 'adam',\n",
       " 'lang',\n",
       " 'carrotparsnip',\n",
       " 'craves',\n",
       " 'combibation',\n",
       " 'spraying',\n",
       " 'discoloring',\n",
       " 'badge',\n",
       " 'bevvie',\n",
       " 'euchre',\n",
       " 'nightsit',\n",
       " 'sneek',\n",
       " 'aduki',\n",
       " 'tasing',\n",
       " 'afghanistan',\n",
       " 'delhis',\n",
       " 'karim',\n",
       " 'afghani',\n",
       " 'zwt06needs',\n",
       " 'chef2chefnet',\n",
       " 'wingslook',\n",
       " 'ratchet',\n",
       " 'bellingham',\n",
       " 'colophon',\n",
       " 'fairhaven',\n",
       " 'youcan',\n",
       " 'mommom',\n",
       " 'habitforming',\n",
       " 'shishkebab',\n",
       " 'outcomethis',\n",
       " 'httpwwwdrinksmixercomdrink754html',\n",
       " 'gullah',\n",
       " 'daufuskie',\n",
       " 'aghios',\n",
       " 'byzantine',\n",
       " '27th',\n",
       " 'iit',\n",
       " 'congregation',\n",
       " 'forgive',\n",
       " 'agios',\n",
       " 'saveurs',\n",
       " 'sweettartand',\n",
       " 'spiceso',\n",
       " 'anywayenjoy',\n",
       " 'limeadeit',\n",
       " 'makeeven',\n",
       " 'overpoweryou',\n",
       " 'thiscook',\n",
       " 'timeoriginally',\n",
       " 'wwwlaylitacomrecipes',\n",
       " 'zwt06',\n",
       " 'billiards',\n",
       " 'extrasharp',\n",
       " 'garlicladen',\n",
       " 'klamath',\n",
       " 'indiginous',\n",
       " 'backgrounds',\n",
       " 'scholar',\n",
       " 'fernando',\n",
       " 'ortiz',\n",
       " 'amerindians',\n",
       " 'papapotato',\n",
       " 'malanga',\n",
       " 'arum',\n",
       " 'boniatosweet',\n",
       " 'cassavaand',\n",
       " 'ajipepper',\n",
       " 'spaniards',\n",
       " 'calabazapumpkin',\n",
       " 'nabo',\n",
       " 'nameyams',\n",
       " 'mestizajemixture',\n",
       " 'races',\n",
       " 'civilization',\n",
       " 'flux',\n",
       " 'cubanstylecut',\n",
       " 'sonia',\n",
       " 'aserecomms',\n",
       " 'ramona',\n",
       " 'abellas',\n",
       " 'srta',\n",
       " 'antonieta',\n",
       " 'reyes',\n",
       " 'gavilan',\n",
       " 'moenks',\n",
       " 'delicias',\n",
       " 'foccaccia',\n",
       " 'iswas',\n",
       " 'saturdaybefore',\n",
       " 'castroand',\n",
       " 'camel',\n",
       " 'nowadaysi',\n",
       " 'mexicana',\n",
       " 'huntsville',\n",
       " 'nowell',\n",
       " 'flashy',\n",
       " 'doevres',\n",
       " 'bonefish',\n",
       " 'moors',\n",
       " 'midfifteenth',\n",
       " 'circuit',\n",
       " 'miserable',\n",
       " 'os',\n",
       " 'hadthanks',\n",
       " 'vickie',\n",
       " 'preferstart',\n",
       " 'alexs',\n",
       " 'punctuation',\n",
       " 'downloaded',\n",
       " 'algarve',\n",
       " 'bechemel',\n",
       " 'httpradiancerecipescomchinesespringrolls',\n",
       " 'transaltes',\n",
       " 'youcef',\n",
       " 'worseinstead',\n",
       " 'dusky',\n",
       " 'lightmay',\n",
       " 'morericeier',\n",
       " 'teacherranch',\n",
       " 'rawfoodtalkcom',\n",
       " 'nameit',\n",
       " 'dolan',\n",
       " 'hostessed',\n",
       " 'anyplace',\n",
       " 'dehydrate',\n",
       " 'muffinbread',\n",
       " 'orchestra',\n",
       " 'gormet',\n",
       " 'meatpossibilities',\n",
       " 'waterlol',\n",
       " 'ingested',\n",
       " 'childreni',\n",
       " 'compartments',\n",
       " 'annoying',\n",
       " 'amen',\n",
       " 'sneezing',\n",
       " 'itchywatery',\n",
       " 'weeds',\n",
       " 'heartbreaking',\n",
       " 'relief',\n",
       " 'translucent',\n",
       " 'goldenbrown',\n",
       " 'counterpoint',\n",
       " 'secondthese',\n",
       " 'ciatrained',\n",
       " 'neverbeforetriedfritters',\n",
       " 'frachelimecayenne',\n",
       " 'neverbefore',\n",
       " 'alongthe',\n",
       " 'secondthe',\n",
       " 'resultsthe',\n",
       " 'clawsfor',\n",
       " 'pearalligator',\n",
       " 'wholl',\n",
       " 'outif',\n",
       " 'noticeallow',\n",
       " 'muchnoteyou',\n",
       " 'onetoone',\n",
       " 'itchyenjoy',\n",
       " 'roach',\n",
       " 'gatorfest',\n",
       " '526666s',\n",
       " 'whitecap',\n",
       " 'roastloaf',\n",
       " 'loverly',\n",
       " 'onecup',\n",
       " 'ohios',\n",
       " 'breaktime',\n",
       " 'chewycrisp',\n",
       " 'annathe',\n",
       " 'mistressi',\n",
       " 'crustmaking',\n",
       " 'piecook',\n",
       " 'timefor',\n",
       " 'recipesliced',\n",
       " 'almostlikefriedchicken',\n",
       " 'odensecom',\n",
       " 'httpwwwsolofoodscomcprodhtml',\n",
       " 'convuluted',\n",
       " 'ccoking',\n",
       " 'tastygreat',\n",
       " 'girlits',\n",
       " 'beforeassembling',\n",
       " 'kewra',\n",
       " 'kheer',\n",
       " 'scully',\n",
       " 'prerolled',\n",
       " 'plainoldchicken',\n",
       " 'journalconstitution',\n",
       " 'kessler',\n",
       " 'plugra',\n",
       " 'madeyoull',\n",
       " 'subjectivedoes',\n",
       " 'alsosource',\n",
       " 'aunties',\n",
       " 'withdrawal',\n",
       " 'goldstar',\n",
       " 'heresy',\n",
       " 'ans',\n",
       " 'risingfermenting',\n",
       " 'castaluminum',\n",
       " 'pleaded',\n",
       " 'tortuga',\n",
       " 'whalers',\n",
       " 'vanille',\n",
       " 'sailu',\n",
       " 'aloo',\n",
       " 'baingan',\n",
       " 'paranthas',\n",
       " 'makethis',\n",
       " 'prework',\n",
       " 'alsatian',\n",
       " 'kronberg',\n",
       " 'mcgavin',\n",
       " 'aerator',\n",
       " 'equates',\n",
       " 'alfree',\n",
       " 'pyrophosphate',\n",
       " 'coronas',\n",
       " 'nanaimo',\n",
       " 'runnier',\n",
       " 'morroccan',\n",
       " 'hodgepodge',\n",
       " 'germanamericans',\n",
       " 'teafall',\n",
       " 'wwwbobsredmillcom',\n",
       " 'parlors',\n",
       " 'worrisome',\n",
       " 'micowave',\n",
       " 'pickme',\n",
       " 'modest',\n",
       " 'gauteng',\n",
       " 'tenderfalls',\n",
       " 'bonetime',\n",
       " 'soundspromise',\n",
       " 'tartlike',\n",
       " '57lb',\n",
       " 'vanillaenjoy',\n",
       " 'cookiesit',\n",
       " 'onperfecting',\n",
       " 'guessthesecretingredient',\n",
       " 'lardmargarine',\n",
       " 'motto',\n",
       " 'forgone',\n",
       " 'juciest',\n",
       " 'experiementing',\n",
       " 'pastto',\n",
       " 'servedip',\n",
       " 'affixed',\n",
       " 'rallied',\n",
       " 'junket',\n",
       " 'zester',\n",
       " 'wwwlaguna2001com',\n",
       " 'pototoes',\n",
       " 'penn',\n",
       " 'itamish',\n",
       " 'pertain',\n",
       " '1one',\n",
       " 'workbut',\n",
       " 'chillequilles',\n",
       " 'enoughseason',\n",
       " 'theodore',\n",
       " 'kyriakou',\n",
       " 'coauthored',\n",
       " 'campion',\n",
       " 'invaded',\n",
       " 'preventitive',\n",
       " 'unrinary',\n",
       " 'andaljucian',\n",
       " 'tucking',\n",
       " 'minors',\n",
       " 'viestad',\n",
       " 'liketo',\n",
       " 'fairfield',\n",
       " 'enricher',\n",
       " 'corpuscle',\n",
       " 'containsdisclaimer',\n",
       " 'stuevens',\n",
       " 'horsch',\n",
       " 'resaturant',\n",
       " 'resturantsbakery',\n",
       " 'yesrefreshingly',\n",
       " 'saucey',\n",
       " 'bestit',\n",
       " 'doubleduty',\n",
       " 'pleasurable',\n",
       " 'vinegarposted',\n",
       " 'iceberglike',\n",
       " 'steaminghot',\n",
       " 'jerez',\n",
       " 'tummies',\n",
       " 'colicky',\n",
       " 'theeffort',\n",
       " 'errands',\n",
       " 'anns',\n",
       " 'skier',\n",
       " 'stewwhatever',\n",
       " 'sheds',\n",
       " 'flakesthats',\n",
       " 'flakesdont',\n",
       " 'reentry',\n",
       " 'spruces',\n",
       " 'scdrecipecom',\n",
       " 'crohns',\n",
       " 'colitis',\n",
       " 'diverticulitis',\n",
       " 'sibo',\n",
       " 'adhd',\n",
       " 'gottschalls',\n",
       " 'vicious',\n",
       " 'cures',\n",
       " 'delicioustastes',\n",
       " 'cookoutscooking',\n",
       " 'juicehoney',\n",
       " 'alsotoni',\n",
       " 'louisana',\n",
       " 'grouprecipescomat',\n",
       " 'orleansstyle',\n",
       " 'pushcarts',\n",
       " 'amarillo',\n",
       " 'wwwtiendacom',\n",
       " 'stoned',\n",
       " 'appetizerthey',\n",
       " 'oftenrequested',\n",
       " 'teaspoonfull',\n",
       " 'pantrynot',\n",
       " 'aoc',\n",
       " 'cavolo',\n",
       " 'laciniato',\n",
       " 'ovenalso',\n",
       " 'jonathan',\n",
       " 'cortland',\n",
       " 'empire',\n",
       " 'winesap',\n",
       " 'glistens',\n",
       " 'alreadysimmered',\n",
       " 'mincemeatlike',\n",
       " 'httpwwwthe4cscomcathyapplesrelishhtml',\n",
       " 'kickedup',\n",
       " 'muffintype',\n",
       " 'cwa',\n",
       " 'retaurant',\n",
       " 'heatthy',\n",
       " 'enjoymakes',\n",
       " 'recipetimes',\n",
       " 'approximateand',\n",
       " 'crepesyou',\n",
       " 'unfilled',\n",
       " 'healthygreenkitchencom',\n",
       " 'pancakewaffle',\n",
       " '15thcentury',\n",
       " 'crackersit',\n",
       " 'sutherland',\n",
       " 'smiththis',\n",
       " 'textureit',\n",
       " 'applesjust',\n",
       " 'yummmdoughnuts',\n",
       " 'sugarsweetness',\n",
       " 'hubbyapproved',\n",
       " 'devoid',\n",
       " 'note2',\n",
       " 'revive',\n",
       " 'pocketsized',\n",
       " 'kitchenits',\n",
       " 'cakesalways',\n",
       " 'birdalso',\n",
       " 'feelalso',\n",
       " 'preferfrom',\n",
       " 'storedprepare',\n",
       " 'janelle',\n",
       " 'includingapples',\n",
       " 'delishi',\n",
       " 'mikie',\n",
       " 'vendorgrowers',\n",
       " 'camino',\n",
       " 'eddiebear',\n",
       " 'alcoholly',\n",
       " 'ovarian',\n",
       " 'cyst',\n",
       " 'removedbut',\n",
       " 'walking',\n",
       " 'koodos',\n",
       " 'excellentit',\n",
       " 'httpwwwindianfoodforevercom',\n",
       " 'champions',\n",
       " 'consume',\n",
       " 'bartype',\n",
       " '44g',\n",
       " '77g',\n",
       " 'chrstmas',\n",
       " 'bruton',\n",
       " 'wied',\n",
       " 'kingauthorflourcom',\n",
       " 'kathryn',\n",
       " 'esham',\n",
       " 'intertwine',\n",
       " 'coax',\n",
       " 'incourtesy',\n",
       " 'cinnamonginger',\n",
       " 'raisinssuperb',\n",
       " 'coolwhip',\n",
       " 'shovel',\n",
       " 'grandmother2110',\n",
       " 'struesel',\n",
       " 'mostess',\n",
       " 'greenwise',\n",
       " 'marr',\n",
       " 'scaleddown',\n",
       " 'subscriber',\n",
       " 'fahey',\n",
       " 'fergus',\n",
       " 'wereso',\n",
       " 'tb',\n",
       " 'galas',\n",
       " 'spearmint',\n",
       " 'myswitzerland',\n",
       " 'everones',\n",
       " 'commitments',\n",
       " 'conspired',\n",
       " 'sauage',\n",
       " 'lookslikeyoufussed',\n",
       " 'drivethru',\n",
       " 'inthecar',\n",
       " 'chums',\n",
       " 'lowes',\n",
       " 'tremendous',\n",
       " 'rollup',\n",
       " 'mexiranch',\n",
       " 'skinnytastecom',\n",
       " 'motherdaughter',\n",
       " 'nonchocolate',\n",
       " 'harold',\n",
       " 'rotary',\n",
       " 'freshener',\n",
       " 'seneca',\n",
       " 'tohquick',\n",
       " 'cupsi',\n",
       " 'freewonderful',\n",
       " 'saladhttpdosesofnourishmentblogspotcom201002livingglutenfreehtml',\n",
       " 'crehan',\n",
       " 'blenheim',\n",
       " 'vegemight',\n",
       " 'prue',\n",
       " 'secs',\n",
       " 'minicarrots',\n",
       " 'peek',\n",
       " 'thoughtful',\n",
       " '1tbps',\n",
       " 'hmmdid',\n",
       " 'farimount',\n",
       " 'fattys',\n",
       " 'stanton',\n",
       " 'vaugtin',\n",
       " 'rugby',\n",
       " 'tonic',\n",
       " 'gogh',\n",
       " 'belvedere',\n",
       " 'ream',\n",
       " 'cokingvilagecom',\n",
       " 'fools',\n",
       " 'wether',\n",
       " 'enjoyedtime',\n",
       " 'stoves',\n",
       " 'ices',\n",
       " 'kareem',\n",
       " 'arancini',\n",
       " 'arbys',\n",
       " 'jamocha',\n",
       " 'shakei',\n",
       " 'dreyers',\n",
       " 'drinkswap',\n",
       " 'preferrecipe',\n",
       " 'httpwwwfoodnetworkcarecipesmainbeefrecipehtmldishid10409',\n",
       " 'recitopia',\n",
       " 'wwwwwrecipescom',\n",
       " 'gwen',\n",
       " 'moseley',\n",
       " 'httpwwwtopsecretrecipescom',\n",
       " 'minfrom',\n",
       " 'oneprep',\n",
       " 'nathaniel',\n",
       " 'chedder',\n",
       " 'cheeselettuce',\n",
       " 'marathon',\n",
       " 'quesstimate',\n",
       " 'klevo',\n",
       " 'liberate',\n",
       " 'ottoman',\n",
       " 'bury',\n",
       " 'betray',\n",
       " 'presence',\n",
       " 'ottomans',\n",
       " 'jk',\n",
       " 'recipe424266',\n",
       " 'gandules',\n",
       " 'bijol',\n",
       " 'turmericthis',\n",
       " 'recipeeveryone',\n",
       " 'spainrecipescom',\n",
       " 'jorge',\n",
       " 'ayala',\n",
       " 'thowdown',\n",
       " 'jorges',\n",
       " 'backyardsthis',\n",
       " 'rattled',\n",
       " 'trythis',\n",
       " 'retailers',\n",
       " 'subsitution',\n",
       " 'informationupdate',\n",
       " 'worcestershireenjoy',\n",
       " 'bolivia',\n",
       " '32nd',\n",
       " 'alternations',\n",
       " 'bolivian',\n",
       " 'kolla',\n",
       " 'marisco',\n",
       " 'fiftytwo',\n",
       " 'simpletakes',\n",
       " 'antipasta',\n",
       " 'castroville',\n",
       " 'perez',\n",
       " 'magana',\n",
       " 'auto',\n",
       " 'petersburg',\n",
       " 'jeffersonday',\n",
       " 'recipescoms',\n",
       " 'spengler',\n",
       " 'menone',\n",
       " 'caymandesigns',\n",
       " 'uncased',\n",
       " 'timesaver',\n",
       " 'forked',\n",
       " 'dilemma',\n",
       " 'oukosherorg',\n",
       " 'crutons',\n",
       " 'authorteacher',\n",
       " 'yuuuuuuummmy',\n",
       " 'elecrtic',\n",
       " 'daywas',\n",
       " 'dayhas',\n",
       " 'jalpeno',\n",
       " 'cilantrommmmm',\n",
       " 'diabretic',\n",
       " 'challengei',\n",
       " 'stonger',\n",
       " 'heatadd',\n",
       " 'magazine2003',\n",
       " 'twoflavor',\n",
       " 'itserve',\n",
       " 'riceone',\n",
       " 'porkveal',\n",
       " 'familyfriendly',\n",
       " 'greenlee',\n",
       " 'greenleebellsouthnet',\n",
       " 'accompanining',\n",
       " 'apps',\n",
       " 'tenderloinsi',\n",
       " 'vancouvers',\n",
       " 'bishop',\n",
       " 'cornim',\n",
       " '440g',\n",
       " 'pence',\n",
       " 'portlandoregon',\n",
       " 'westmoreland',\n",
       " 'subjective',\n",
       " 'deliciousthis',\n",
       " 'bussierebermeo',\n",
       " 'concensus',\n",
       " 'dippingservings',\n",
       " 'americanjust',\n",
       " 'ilanna',\n",
       " 'albeit',\n",
       " 'begedil',\n",
       " 'belownote',\n",
       " 'winco',\n",
       " 'rooster',\n",
       " 'elvee',\n",
       " 'jacqus',\n",
       " 'bettercan',\n",
       " 'hooded',\n",
       " 'planking',\n",
       " 'shewchuk',\n",
       " 'tomatobasil',\n",
       " 'easierserve',\n",
       " 'cookbookalthough',\n",
       " 'mealgarlic',\n",
       " 'jenelaine',\n",
       " 'allrecipescomquick',\n",
       " 'unoaked',\n",
       " 'readi',\n",
       " 'wattage',\n",
       " 'differentlyso',\n",
       " 'southerly',\n",
       " 'foose',\n",
       " 'stockon',\n",
       " 'summerspring',\n",
       " 'stockton',\n",
       " 'magnifique',\n",
       " 'creamywine',\n",
       " 'springyness',\n",
       " 'readded',\n",
       " 'purnell',\n",
       " 'potpie',\n",
       " 'zinsmeister',\n",
       " 'slinger',\n",
       " 'recipesubmitted',\n",
       " 'podracky',\n",
       " 'fontaine',\n",
       " 'develope',\n",
       " 'seans',\n",
       " 'audrey',\n",
       " 'hepburn',\n",
       " 'fourme',\n",
       " 'dambert',\n",
       " 'scotlands',\n",
       " 'curtail',\n",
       " 'diplomatic',\n",
       " 'tangible',\n",
       " 'mercenaries',\n",
       " 'armies',\n",
       " 'neverfailstoimpress',\n",
       " 'dick',\n",
       " 'drawl',\n",
       " 'moistfor',\n",
       " 'granule',\n",
       " 'marinadewhat',\n",
       " 'chae',\n",
       " '94990response',\n",
       " 'ancienti',\n",
       " 'aunti',\n",
       " 'invent',\n",
       " 'helens',\n",
       " 'appx',\n",
       " 'unsolicited',\n",
       " 'precursor',\n",
       " 'lunchessuppers',\n",
       " 'calmex',\n",
       " 'tais',\n",
       " 'manufacturing',\n",
       " 'kellysbirmingham',\n",
       " 'alabamaaunt',\n",
       " 'corneliaana',\n",
       " 'christmasnew',\n",
       " 'yearseaster',\n",
       " 'sues',\n",
       " 'onionsbut',\n",
       " 'proscuito',\n",
       " 'weezie',\n",
       " 'ricemeat',\n",
       " 'meltededited',\n",
       " 'maes',\n",
       " 'chocolateis',\n",
       " 'springssomewhere',\n",
       " 'societys',\n",
       " 'perth',\n",
       " 'semillion',\n",
       " 'chiko',\n",
       " 'alldownundercom',\n",
       " 'miettas',\n",
       " 'mozart',\n",
       " 'opera',\n",
       " 'cocktailsoftheworldcom',\n",
       " 'bavarians',\n",
       " 'servingor',\n",
       " 'dharamsala',\n",
       " 'himmachal',\n",
       " 'pradesh',\n",
       " 'talbot',\n",
       " 'veggiesi',\n",
       " 'agowow',\n",
       " 'togethertry',\n",
       " 'oilcured',\n",
       " 'testers',\n",
       " 'recrisp',\n",
       " '450f',\n",
       " 'zipperlock',\n",
       " 'surveyed',\n",
       " 'receta',\n",
       " 'caserra',\n",
       " 'mucha',\n",
       " 'mierdanotethese',\n",
       " 'clayton',\n",
       " 'perspiration',\n",
       " 'forehead',\n",
       " 'bitalso',\n",
       " 'toped',\n",
       " 'heartiness',\n",
       " 'schuhmacher',\n",
       " 'kielbaska',\n",
       " 'outespecially',\n",
       " 'mags2003',\n",
       " 'gush',\n",
       " 'avgolemono',\n",
       " 'realising',\n",
       " 'dieniab',\n",
       " 'delishious',\n",
       " 'clint',\n",
       " 'stephenson',\n",
       " 'friendswood',\n",
       " 'fishspecially',\n",
       " 'soggyby',\n",
       " 'drinkcook',\n",
       " 'ranchito',\n",
       " 'spoonor',\n",
       " 'gread',\n",
       " 'verge',\n",
       " 'kirkland',\n",
       " 'fridaybut',\n",
       " 'tying',\n",
       " 'lakeside',\n",
       " 'yummychill',\n",
       " 'brownes',\n",
       " 'handokay',\n",
       " 'gangsta',\n",
       " 'lopez',\n",
       " 'ohiohttpthewebgangstacomindexphp201005awardwinningrecipeforcincodemayoguacamolewithbluecheeseandbaconinspiredbyfoodnetwork',\n",
       " 'morerecipe',\n",
       " 'instructionsprep',\n",
       " 'awesomehence',\n",
       " 'makings',\n",
       " 'wins',\n",
       " 'lettermans',\n",
       " 'gemsanyway',\n",
       " 'syria',\n",
       " 'bummerby',\n",
       " 'jambalayas',\n",
       " 'httpvictoriafamilymealsblogspotca',\n",
       " 'doshafrom',\n",
       " 'yogajournalcom',\n",
       " 'onemeal',\n",
       " 'ontherun',\n",
       " 'ferries',\n",
       " 'horseshoe',\n",
       " 'bistros',\n",
       " 'versionnote',\n",
       " 'grigioupdate',\n",
       " 'bulb',\n",
       " 'b52',\n",
       " 'leta',\n",
       " 'dribble',\n",
       " 'recipegoldmineupdate',\n",
       " 'bab',\n",
       " 'wier',\n",
       " 'followthecookblogspotcom',\n",
       " 'baboons',\n",
       " 'whirr',\n",
       " '18x24inches',\n",
       " 'brwn',\n",
       " 'crackersgoes',\n",
       " 'scouring',\n",
       " 'pediatrician',\n",
       " 'p2',\n",
       " 'aliza',\n",
       " 'thesea',\n",
       " 'officehe',\n",
       " 'prepchillor',\n",
       " 'sizeall',\n",
       " 'quesses',\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "file = pd.read_csv('preprocessed_descriptions.csv', index_col=0)\n",
    "file['preprocessed_descriptions'] = file['preprocessed_descriptions'].apply(str)\n",
    "f = (' ').join(file['preprocessed_descriptions'].values)\n",
    "words = nltk.tokenize.word_tokenize(f)\n",
    "dict1 = nltk.FreqDist(words)\n",
    "words = [word for word, freq in dict1.items() if word.isdigit() == False and freq ==1]\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пара №1 ['quinoa', 'to'] ->-> 5\n",
      "Пара №2 ['beautiful', 'is'] ->-> 8\n",
      "Пара №3 ['thick', 'i'] ->-> 4\n",
      "Пара №4 ['hooded', 'the'] ->-> 5\n",
      "Пара №5 ['the', 'coconut'] ->-> 7\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "f = (' ').join(file['preprocessed_descriptions'].values)\n",
    "words = nltk.tokenize.word_tokenize(f)\n",
    "s = [sample(words, 2) for _ in range(5)]\n",
    "for i in range(5):\n",
    "    print(f'Пара №{i+1} {s[i]} ->-> {edit_distance(s[i][0], s[i][1])}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('monday', 0), ('sunday', 2), ('today', 2), ('money', 2)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(word,k):\n",
    "    f = (' ').join(file['preprocessed_descriptions'].values)\n",
    "    words = nltk.tokenize.word_tokenize(f)\n",
    "    mini = 10**6\n",
    "    close_to_word = {i:(edit_distance(word,i)) for i in words}\n",
    "    return sorted(close_to_word.items(), key=lambda item: item[1])[:k]\n",
    "f('monday',4)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>georges</th>\n",
       "      <td>georges</td>\n",
       "      <td>george</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>its</th>\n",
       "      <td>its</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>children</td>\n",
       "      <td>child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friends</th>\n",
       "      <td>friends</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popsicles</th>\n",
       "      <td>popsicles</td>\n",
       "      <td>popsicle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sites</th>\n",
       "      <td>sites</td>\n",
       "      <td>site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>its</th>\n",
       "      <td>its</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roots</th>\n",
       "      <td>roots</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cookies</th>\n",
       "      <td>cookies</td>\n",
       "      <td>cooky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cookies</th>\n",
       "      <td>cookies</td>\n",
       "      <td>cooky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77095 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          stemmed_word normalized_word\n",
       "word                                  \n",
       "georges        georges          george\n",
       "its                its              it\n",
       "children      children           child\n",
       "friends        friends          friend\n",
       "popsicles    popsicles        popsicle\n",
       "...                ...             ...\n",
       "sites            sites            site\n",
       "its                its              it\n",
       "roots            roots            root\n",
       "cookies        cookies           cooky\n",
       "cookies        cookies           cooky\n",
       "\n",
       "[77095 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snb_stemmer_ru = SnowballStemmer('russian')\n",
    "\n",
    "stemmed  = [snb_stemmer_ru.stem(j) for j in words]\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "normalized = [wnl.lemmatize(i) for i in words]\n",
    "df = pd.DataFrame({'word':words,'stemmed_word':stemmed,'normalized_word':normalized})\n",
    "df = df.set_index('word')\n",
    "df[df['stemmed_word']!=df['normalized_word']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>preprocessed_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>george s at the cove  black bean soup</td>\n",
       "      <td>an original recipe created by chef scott meska...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>healthy for them  yogurt popsicles</td>\n",
       "      <td>my children and their friends ask for my homem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i can t believe it s spinach</td>\n",
       "      <td>these were so go it surprised even me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>italian  gut busters</td>\n",
       "      <td>my sisterinlaw made these for us at a family g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love is in the air  beef fondue   sauces</td>\n",
       "      <td>i think a fondue is a very romantic casual din...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>zurie s holey rustic olive and cheddar bread</td>\n",
       "      <td>this is based on a french recipe but i changed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>zwetschgenkuchen  bavarian plum cake</td>\n",
       "      <td>this is a traditional fresh plum cake thought ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>zwiebelkuchen   southwest german onion cake</td>\n",
       "      <td>this is a traditional late summer early fall s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>zydeco soup</td>\n",
       "      <td>this is a delicious soup that i originally fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>cookies by design   cookies on a stick</td>\n",
       "      <td>ive heard of the cookies by design company but...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               name  \\\n",
       "0             george s at the cove  black bean soup   \n",
       "1                healthy for them  yogurt popsicles   \n",
       "2                      i can t believe it s spinach   \n",
       "3                              italian  gut busters   \n",
       "4          love is in the air  beef fondue   sauces   \n",
       "...                                             ...   \n",
       "29995  zurie s holey rustic olive and cheddar bread   \n",
       "29996          zwetschgenkuchen  bavarian plum cake   \n",
       "29997   zwiebelkuchen   southwest german onion cake   \n",
       "29998                                   zydeco soup   \n",
       "29999        cookies by design   cookies on a stick   \n",
       "\n",
       "                               preprocessed_descriptions  \n",
       "0      an original recipe created by chef scott meska...  \n",
       "1      my children and their friends ask for my homem...  \n",
       "2                  these were so go it surprised even me  \n",
       "3      my sisterinlaw made these for us at a family g...  \n",
       "4      i think a fondue is a very romantic casual din...  \n",
       "...                                                  ...  \n",
       "29995  this is based on a french recipe but i changed...  \n",
       "29996  this is a traditional fresh plum cake thought ...  \n",
       "29997  this is a traditional late summer early fall s...  \n",
       "29998  this is a delicious soup that i originally fou...  \n",
       "29999  ive heard of the cookies by design company but...  \n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "stop_word = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Стоп-слова составляют 0.46 долю от общего количества слов. \n"
     ]
    }
   ],
   "source": [
    "f = (' ').join(file['preprocessed_descriptions'].values)\n",
    "words = nltk.tokenize.word_tokenize(f)\n",
    "good_words = []\n",
    "k=0\n",
    "for i in words:\n",
    "    if i not in stop_word:\n",
    "        good_words.append(i)\n",
    "    else:\n",
    "        k+=1\n",
    "print(f'Стоп-слова составляют {round(k/len(words),2)} долю от общего количества слов. ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "stop_word = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 самых часто встречающихся слов до удаления стоп-слов: the; a; and; this; i; to; is; it; of; for. \n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "str_words = (' ').join(words)\n",
    "words_tokens = [t.text.lower() for t in tokenize(str_words)]    \n",
    "fdist = FreqDist(words_tokens)\n",
    "print(f'10 самых часто встречающихся слов до удаления стоп-слов: {(\"; \").join(list(map(lambda x: x[0],fdist.most_common(10))))}. ')\n",
    "      \n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 самых часто встречающихся слов после удаления стоп-слов: recipe; make; time; use; great; like; easy; one; made; good.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "str_words = (' ').join(good_words)\n",
    "words_tokens = [t.text.lower() for t in tokenize(str_words)]    \n",
    "fdist = FreqDist(words_tokens)\n",
    "print(f'10 самых часто встречающихся слов после удаления стоп-слов: {(\"; \").join(list(map(lambda x: x[0],fdist.most_common(10))))}.')\n",
    "      \n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.14769735,\n",
       "        0.13108086, 0.        , 0.        , 0.13108086, 0.26216173,\n",
       "        0.        , 0.13108086, 0.        , 0.13108086, 0.13108086,\n",
       "        0.        , 0.        , 0.13108086, 0.13108086, 0.        ,\n",
       "        0.13108086, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.13108086, 0.        , 0.13108086, 0.08778638,\n",
       "        0.10575522, 0.        , 0.13108086, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13108086, 0.10575522, 0.        ,\n",
       "        0.        , 0.        , 0.13108086, 0.14769735, 0.17557277,\n",
       "        0.        , 0.        , 0.13108086, 0.        , 0.13108086,\n",
       "        0.13108086, 0.        , 0.        , 0.13108086, 0.10575522,\n",
       "        0.        , 0.13108086, 0.13108086, 0.        , 0.13108086,\n",
       "        0.13108086, 0.10575522, 0.        , 0.10575522, 0.13108086,\n",
       "        0.        , 0.        , 0.        , 0.13108086, 0.        ,\n",
       "        0.13108086, 0.13108086, 0.13108086, 0.13108086, 0.        ,\n",
       "        0.        , 0.08778638, 0.        , 0.        , 0.13108086,\n",
       "        0.        , 0.        , 0.13108086, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.21151043, 0.26216173, 0.        ,\n",
       "        0.13108086, 0.        , 0.10575522, 0.13108086, 0.1873822 ,\n",
       "        0.07384867, 0.        , 0.        , 0.13108086, 0.13108086,\n",
       "        0.        , 0.13108086, 0.        , 0.        , 0.        ,\n",
       "        0.13108086, 0.        , 0.10575522, 0.08778638, 0.        ],\n",
       "       [0.        , 0.13812029, 0.13812029, 0.13812029, 0.15562912,\n",
       "        0.        , 0.13812029, 0.13812029, 0.        , 0.        ,\n",
       "        0.13812029, 0.        , 0.13812029, 0.        , 0.        ,\n",
       "        0.        , 0.13812029, 0.        , 0.        , 0.13812029,\n",
       "        0.        , 0.        , 0.13812029, 0.13812029, 0.        ,\n",
       "        0.13812029, 0.        , 0.13812029, 0.        , 0.13812029,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.09250077,\n",
       "        0.        , 0.        , 0.        , 0.13812029, 0.13812029,\n",
       "        0.        , 0.13812029, 0.        , 0.11143458, 0.11143458,\n",
       "        0.13812029, 0.13812029, 0.        , 0.15562912, 0.09250077,\n",
       "        0.        , 0.13812029, 0.        , 0.13812029, 0.        ,\n",
       "        0.        , 0.27624057, 0.        , 0.        , 0.11143458,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.11143458, 0.13812029, 0.        , 0.        ,\n",
       "        0.        , 0.13812029, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.13812029,\n",
       "        0.        , 0.09250077, 0.        , 0.13812029, 0.        ,\n",
       "        0.13812029, 0.13812029, 0.        , 0.13812029, 0.13812029,\n",
       "        0.        , 0.13812029, 0.        , 0.        , 0.13812029,\n",
       "        0.        , 0.13812029, 0.22286916, 0.        , 0.06581506,\n",
       "        0.        , 0.13812029, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.27624057, 0.        ,\n",
       "        0.        , 0.13812029, 0.11143458, 0.09250077, 0.        ],\n",
       "       [0.2433832 , 0.        , 0.        , 0.        , 0.27423569,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.2433832 ,\n",
       "        0.        , 0.2433832 , 0.        , 0.2433832 , 0.        ,\n",
       "        0.2433832 , 0.        , 0.2433832 , 0.        , 0.16299656,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.19636003, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.13711785, 0.        ,\n",
       "        0.2433832 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2433832 , 0.        , 0.        , 0.2433832 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2433832 , 0.        , 0.2433832 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2433832 , 0.        , 0.2433832 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19636003, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1159734 ,\n",
       "        0.13711785, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.34721378, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2801299 , 0.34721378, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.23253312,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.2801299 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.34721378,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.34721378, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16544923,\n",
       "        0.19561419, 0.        , 0.34721378, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.34721378, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.19463915,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.34548309, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.27873358, 0.        , 0.        , 0.        , 0.27873358,\n",
       "        0.        , 0.        , 0.        , 0.19463915, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.34548309, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.23137405, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16462454,\n",
       "        0.19463915, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.34548309, 0.        , 0.        , 0.        , 0.34548309,\n",
       "        0.        , 0.        , 0.        , 0.23137405, 0.34548309]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import (CountVectorizer, TfidfVectorizer)\n",
    "a = (file.sample(5))\n",
    "arr_name =  a.name\n",
    "arr_desc = a.preprocessed_descriptions\n",
    "# создание векторизатора:\n",
    "tv = TfidfVectorizer()\n",
    "# векторизуем корпус:\n",
    "corpus_tv = tv.fit_transform(arr_desc)\n",
    "corpus_tv = corpus_tv.toarray()\n",
    "corpus_tv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filet mignon with cherry balsamic reduction',\n",
       " 'prawns  large shrimp  topped with crabmeat',\n",
       " 'bow ties and scallops',\n",
       " 'apples and cinnamon breakfast quinoa',\n",
       " 'blueberry stuffed french toast']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_name =list(arr_name)\n",
    "arr_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filet mignon with cherry balsamic reduction</th>\n",
       "      <th>prawns  large shrimp  topped with crabmeat</th>\n",
       "      <th>bow ties and scallops</th>\n",
       "      <th>apples and cinnamon breakfast quinoa</th>\n",
       "      <th>blueberry stuffed french toast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>filet mignon with cherry balsamic reduction</th>\n",
       "      <td>1</td>\n",
       "      <td>0.169615</td>\n",
       "      <td>0.148454</td>\n",
       "      <td>0.145525</td>\n",
       "      <td>0.14334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prawns  large shrimp  topped with crabmeat</th>\n",
       "      <td>0.169615</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086729</td>\n",
       "      <td>0.032399</td>\n",
       "      <td>0.145283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bow ties and scallops</th>\n",
       "      <td>0.148454</td>\n",
       "      <td>0.086729</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04601</td>\n",
       "      <td>0.180578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apples and cinnamon breakfast quinoa</th>\n",
       "      <td>0.145525</td>\n",
       "      <td>0.032399</td>\n",
       "      <td>0.04601</td>\n",
       "      <td>1</td>\n",
       "      <td>0.065311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blueberry stuffed french toast</th>\n",
       "      <td>0.14334</td>\n",
       "      <td>0.145283</td>\n",
       "      <td>0.180578</td>\n",
       "      <td>0.065311</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filet mignon with cherry balsamic reduction  \\\n",
       "filet mignon with cherry balsamic reduction                                           1   \n",
       "prawns  large shrimp  topped with crabmeat                                     0.169615   \n",
       "bow ties and scallops                                                          0.148454   \n",
       "apples and cinnamon breakfast quinoa                                           0.145525   \n",
       "blueberry stuffed french toast                                                  0.14334   \n",
       "\n",
       "                                            prawns  large shrimp  topped with crabmeat  \\\n",
       "filet mignon with cherry balsamic reduction                                   0.169615   \n",
       "prawns  large shrimp  topped with crabmeat                                           1   \n",
       "bow ties and scallops                                                         0.086729   \n",
       "apples and cinnamon breakfast quinoa                                          0.032399   \n",
       "blueberry stuffed french toast                                                0.145283   \n",
       "\n",
       "                                            bow ties and scallops  \\\n",
       "filet mignon with cherry balsamic reduction              0.148454   \n",
       "prawns  large shrimp  topped with crabmeat               0.086729   \n",
       "bow ties and scallops                                           1   \n",
       "apples and cinnamon breakfast quinoa                      0.04601   \n",
       "blueberry stuffed french toast                           0.180578   \n",
       "\n",
       "                                            apples and cinnamon breakfast quinoa  \\\n",
       "filet mignon with cherry balsamic reduction                             0.145525   \n",
       "prawns  large shrimp  topped with crabmeat                              0.032399   \n",
       "bow ties and scallops                                                    0.04601   \n",
       "apples and cinnamon breakfast quinoa                                           1   \n",
       "blueberry stuffed french toast                                          0.065311   \n",
       "\n",
       "                                            blueberry stuffed french toast  \n",
       "filet mignon with cherry balsamic reduction                        0.14334  \n",
       "prawns  large shrimp  topped with crabmeat                        0.145283  \n",
       "bow ties and scallops                                             0.180578  \n",
       "apples and cinnamon breakfast quinoa                              0.065311  \n",
       "blueberry stuffed french toast                                           1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(index = arr_name, columns = arr_name)\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        d = distance.cosine(corpus_tv[i],corpus_tv[j])\n",
    "        df[arr_name[i]][arr_name[j]] = 1-d\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = df.values.max()\n",
    "max_val\n",
    "df[df ==1] = -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filet mignon with cherry balsamic reduction</th>\n",
       "      <th>prawns  large shrimp  topped with crabmeat</th>\n",
       "      <th>bow ties and scallops</th>\n",
       "      <th>apples and cinnamon breakfast quinoa</th>\n",
       "      <th>blueberry stuffed french toast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>filet mignon with cherry balsamic reduction</th>\n",
       "      <td>-10</td>\n",
       "      <td>0.169615</td>\n",
       "      <td>0.148454</td>\n",
       "      <td>0.145525</td>\n",
       "      <td>0.14334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prawns  large shrimp  topped with crabmeat</th>\n",
       "      <td>0.169615</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.086729</td>\n",
       "      <td>0.032399</td>\n",
       "      <td>0.145283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bow ties and scallops</th>\n",
       "      <td>0.148454</td>\n",
       "      <td>0.086729</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.04601</td>\n",
       "      <td>0.180578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apples and cinnamon breakfast quinoa</th>\n",
       "      <td>0.145525</td>\n",
       "      <td>0.032399</td>\n",
       "      <td>0.04601</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.065311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blueberry stuffed french toast</th>\n",
       "      <td>0.14334</td>\n",
       "      <td>0.145283</td>\n",
       "      <td>0.180578</td>\n",
       "      <td>0.065311</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filet mignon with cherry balsamic reduction  \\\n",
       "filet mignon with cherry balsamic reduction                                         -10   \n",
       "prawns  large shrimp  topped with crabmeat                                     0.169615   \n",
       "bow ties and scallops                                                          0.148454   \n",
       "apples and cinnamon breakfast quinoa                                           0.145525   \n",
       "blueberry stuffed french toast                                                  0.14334   \n",
       "\n",
       "                                            prawns  large shrimp  topped with crabmeat  \\\n",
       "filet mignon with cherry balsamic reduction                                   0.169615   \n",
       "prawns  large shrimp  topped with crabmeat                                         -10   \n",
       "bow ties and scallops                                                         0.086729   \n",
       "apples and cinnamon breakfast quinoa                                          0.032399   \n",
       "blueberry stuffed french toast                                                0.145283   \n",
       "\n",
       "                                            bow ties and scallops  \\\n",
       "filet mignon with cherry balsamic reduction              0.148454   \n",
       "prawns  large shrimp  topped with crabmeat               0.086729   \n",
       "bow ties and scallops                                         -10   \n",
       "apples and cinnamon breakfast quinoa                      0.04601   \n",
       "blueberry stuffed french toast                           0.180578   \n",
       "\n",
       "                                            apples and cinnamon breakfast quinoa  \\\n",
       "filet mignon with cherry balsamic reduction                             0.145525   \n",
       "prawns  large shrimp  topped with crabmeat                              0.032399   \n",
       "bow ties and scallops                                                    0.04601   \n",
       "apples and cinnamon breakfast quinoa                                         -10   \n",
       "blueberry stuffed french toast                                          0.065311   \n",
       "\n",
       "                                            blueberry stuffed french toast  \n",
       "filet mignon with cherry balsamic reduction                        0.14334  \n",
       "prawns  large shrimp  topped with crabmeat                        0.145283  \n",
       "bow ties and scallops                                             0.180578  \n",
       "apples and cinnamon breakfast quinoa                              0.065311  \n",
       "blueberry stuffed french toast                                         -10  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bow ties and scallops и blueberry stuffed french toast'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Находим максимальный элемент и его индексы\n",
    "def max_value():\n",
    "    max_val = df.values.max()\n",
    "    for i in (arr_name):\n",
    "        for j in (arr_name):\n",
    "            if df[i][j] == max_val:\n",
    "                return (' и ').join([i,j])\n",
    "max_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
