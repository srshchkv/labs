{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "     -------------------------------------- 55.5/55.5 kB 718.1 kB/s eta 0:00:00\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "     ---------------------------------------- 8.2/8.2 MB 5.1 MB/s eta 0:00:00\n",
      "Collecting docopt>=0.6\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting dawg-python>=0.7.1\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=0b95ebac182fbea7485034112201d1513acc34334a5e6adbeb9c6f1d80571c0d\n",
      "  Stored in directory: c:\\users\\zerka\\appdata\\local\\pip\\cache\\wheels\\70\\4a\\46\\1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
      "Successfully built docopt\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
     ]
    }
   ],
   "source": [
    "%pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['облагодетельствованным',\n",
       " 'облагодетельствованных',\n",
       " 'председательствовавший',\n",
       " 'стадвадцатипятирублевой',\n",
       " 'высокопревосходительство',\n",
       " 'высокопревосходительства',\n",
       " 'попреблагорассмотрительст',\n",
       " 'попреблагорассмотрительствующемуся',\n",
       " 'убегающих',\n",
       " 'уменьшившейся']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''\n",
    "with open('litw-win.txt') as f:\n",
    "    words = f.readlines()\n",
    "eq = re.compile(r'[а-яА-ЯёЁ]')\n",
    "for i in range(len(words)):\n",
    "    words[i] = ''.join(eq.findall(words[i]))\n",
    "words[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['с',\n",
       " 'величайшим',\n",
       " 'усилием',\n",
       " 'выбравшись',\n",
       " 'из',\n",
       " 'потока',\n",
       " 'убегающих',\n",
       " 'людей',\n",
       " 'кутузов',\n",
       " 'со',\n",
       " 'свитой',\n",
       " 'уменьшившейся',\n",
       " 'вдвое',\n",
       " 'поехал',\n",
       " 'на',\n",
       " 'звуки',\n",
       " 'выстрелов',\n",
       " 'русских',\n",
       " 'орудий']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.metrics import edit_distance\n",
    "text_1 = word_tokenize(text)\n",
    "for i in range(len(text_1)):\n",
    "    if text_1[i] not in words:\n",
    "        text_1[i] = min(words, key = lambda x: edit_distance(text_1[i].lower(), x))\n",
    "text_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Список слов:\n",
      "['Считайте', 'слова', 'из', 'файла', 'litw-win.txt', 'и', 'запишите', 'их', 'в', 'список', 'words', '.', 'В', 'заданном', 'предложении', 'исправьте', 'все', 'опечатки', ',', 'заменив', 'слова', 'с', 'опечатками', 'на', 'ближайшие', '(', 'в', 'смысле', 'расстояния', 'Левенштейна', ')', 'к', 'ним', 'слова', 'из', 'списка', 'words', '.', 'Считайте', ',', 'что', 'в', 'слове', 'есть', 'опечатка', ',', 'если', 'данное', 'слово', 'не', 'содержится', 'в', 'списке', 'words', '.']\n",
      "\n",
      "Стемминг:\n",
      "['счита', 'слов', 'из', 'файл', 'litw-win.txt', 'и', 'запиш', 'их', 'в', 'список', 'words', '.', 'в', 'зада', 'предложен', 'исправьт', 'все', 'опечатк', ',', 'замен', 'слов', 'с', 'опечатк', 'на', 'ближайш', '(', 'в', 'смысл', 'расстоян', 'левенштейн', ')', 'к', 'ним', 'слов', 'из', 'списк', 'words', '.', 'счита', ',', 'что', 'в', 'слов', 'ест', 'опечатк', ',', 'есл', 'дан', 'слов', 'не', 'содерж', 'в', 'списк', 'words', '.']\n",
      "\n",
      "Лемматизация:\n",
      "['Считайте', 'слова', 'из', 'файла', 'litw-win.txt', 'и', 'запишите', 'их', 'в', 'список', 'word', '.', 'В', 'заданном', 'предложении', 'исправьте', 'все', 'опечатки', ',', 'заменив', 'слова', 'с', 'опечатками', 'на', 'ближайшие', '(', 'в', 'смысле', 'расстояния', 'Левенштейна', ')', 'к', 'ним', 'слова', 'из', 'списка', 'word', '.', 'Считайте', ',', 'что', 'в', 'слове', 'есть', 'опечатка', ',', 'если', 'данное', 'слово', 'не', 'содержится', 'в', 'списке', 'word', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "tkns = word_tokenize('''Считайте слова из файла litw-win.txt и запишите их в список words. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words. Считайте, что в слове есть опечатка, если данное слово не содержится в списке words.''')\n",
    "stmmr = SnowballStemmer('russian')\n",
    "lmmtzr = WordNetLemmatizer()\n",
    "stmd = [stmmr.stem(i) for i in tkns]\n",
    "lmtzd = [lmmtzr.lemmatize(i) for i in tkns]\n",
    "print(f'Список слов:\\n{tkns}\\n')\n",
    "print(f'Стемминг:\\n{stmd}\\n')\n",
    "print(f'Лемматизация:\\n{lmtzd}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токены:\n",
      "['litw', 'txt', 'win', 'words', 'ближайшие', 'все', 'данное', 'если', 'есть', 'заданном', 'заменив', 'запишите', 'из', 'исправьте', 'их', 'левенштейна', 'на', 'не', 'ним', 'опечатка', 'опечатками', 'опечатки', 'предложении', 'расстояния', 'слова', 'слове', 'слово', 'смысле', 'содержится', 'списка', 'списке', 'список', 'считайте', 'файла', 'что']\n",
      "\n",
      "[[1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0]\n",
      " [0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 2 0 0 1 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zerka\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "txt = sent_tokenize('''Считайте слова из файла litw-win.txt и запишите их в список words. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words. Считайте, что в слове есть опечатка, если данное слово не содержится в списке words.''')\n",
    "vctrzr = CountVectorizer()\n",
    "vctrzd_txt = vctrzr.fit_transform(txt).toarray()\n",
    "print(f'Токены:\\n{vctrzr.get_feature_names()}\\n')\n",
    "print(vctrzd_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['an', 'original', 'recipe', ..., 'augsburg', 'consensus',\n",
       "       'planted'], dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('preprocessed_descriptions.csv')\n",
    "df['preprocessed_descriptions'] = df['preprocessed_descriptions'].astype(str)\n",
    "words = pd.unique(word_tokenize(' '.join(df['preprocessed_descriptions'].values.tolist()))) #1\n",
    "ord_words = word_tokenize(' '.join(df['preprocessed_descriptions'].values.tolist()))\n",
    "# words = np.unique(word_tokenize(' '.join(df['preprocessed_descriptions'].values.tolist()))) #2\n",
    "# words = set(word_tokenize(' '.join(df['preprocessed_descriptions'].values.tolist()))) #3\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расстояние редактирование между finlayson и adjusts = 8\n",
      "Расстояние редактирование между servingsdepending и bluesand = 14\n",
      "Расстояние редактирование между meltedrevision и enzymatic = 12\n",
      "Расстояние редактирование между romaine и savoury = 7\n",
      "Расстояние редактирование между pides и unles = 3\n"
     ]
    }
   ],
   "source": [
    "rand_words = np.random.choice(words, size=(5, 2))\n",
    "# print(rand_words)\n",
    "for i in rand_words:\n",
    "    print(f'Расстояние редактирование между {i[0]} и {i[1]} = {edit_distance(i[0],i[1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hello', 0), ('hell', 1), ('jello', 1), ('mello', 1)]\n"
     ]
    }
   ],
   "source": [
    "def closet_words(word, k):\n",
    "    lst = [(w,edit_distance(word, w)) for w in words]\n",
    "    lst = sorted(lst, key = lambda x: x[1])\n",
    "    return lst[:k]\n",
    "print(closet_words('hello',4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>georges</th>\n",
       "      <td>georges</td>\n",
       "      <td>george</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>its</th>\n",
       "      <td>its</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>children</td>\n",
       "      <td>child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friends</th>\n",
       "      <td>friends</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popsicles</th>\n",
       "      <td>popsicles</td>\n",
       "      <td>popsicle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renos</th>\n",
       "      <td>renos</td>\n",
       "      <td>reno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smalls</th>\n",
       "      <td>smalls</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>steroids</th>\n",
       "      <td>steroids</td>\n",
       "      <td>steroid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calders</th>\n",
       "      <td>calders</td>\n",
       "      <td>calder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fairies</th>\n",
       "      <td>fairies</td>\n",
       "      <td>fairy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3129 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          stemmed_word normalized_word\n",
       "word                                  \n",
       "georges        georges          george\n",
       "its                its              it\n",
       "children      children           child\n",
       "friends        friends          friend\n",
       "popsicles    popsicles        popsicle\n",
       "...                ...             ...\n",
       "renos            renos            reno\n",
       "smalls          smalls           small\n",
       "steroids      steroids         steroid\n",
       "calders        calders          calder\n",
       "fairies        fairies           fairy\n",
       "\n",
       "[3129 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_words = [stmmr.stem(i) for i in words]\n",
    "# stemmed_word\n",
    "normalized_words = [lmmtzr.lemmatize(i) for i in words]\n",
    "# normalized_word\n",
    "df_1 = pd.DataFrame({'stemmed_word':stemmed_words, 'normalized_word':normalized_words , 'word':words}).set_index('word')\n",
    "df_1[df_1['stemmed_word']!=df_1['normalized_word']] #выведен датафрейм с такой маской, чтобы не показывались одинаковые результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Стоп-слов было 136\n",
      "Доля стоп-слов: 0.004137763173907752\n",
      "Топ 10 самых частых слов до удаления:\n",
      "[('for', 15939), ('of', 18364), ('it', 19756), ('is', 20285), ('to', 23471), ('i', 24836), ('this', 26859), ('and', 30245), ('a', 34951), ('the', 40072)]\n",
      "Топ 10 самых частых слов после удаления:\n",
      "[('good', 3791), ('made', 3810), ('one', 3872), ('easy', 4152), ('like', 4167), ('great', 4430), ('use', 4620), ('time', 5137), ('make', 6326), ('recipe', 14871)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "lst1 = [word for word in words if word.lower() not in set(stopwords.words('english'))]\n",
    "# lst1\n",
    "lst2 = [word for word in ord_words if word.lower() not in set(stopwords.words('english'))]\n",
    "freq_words = list(FreqDist(ord_words).items())\n",
    "freq_wthout_stops = list(FreqDist(lst2).items())\n",
    "print(f'Стоп-слов было {len(words) - len(lst1)}\\nДоля стоп-слов: {(len(words) - len(lst1))/len(words)}')\n",
    "print(f'Топ 10 самых частых слов до удаления:\\n{sorted(freq_words, key = lambda x: x[1])[-10:]}')\n",
    "print(f'Топ 10 самых частых слов после удаления:\\n{sorted(freq_wthout_stops, key = lambda x: x[1])[-10:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3045' 'add' 'adding' 'addition' 'adjust' 'all' 'also' 'amazing' 'an'\n",
      " 'and' 'any' 'army' 'baked' 'barb' 'base' 'be' 'because' 'big' 'bought'\n",
      " 'brown' 'but' 'by' 'can' 'chicken' 'chop' 'coleslaw' 'completely' 'cook'\n",
      " 'cooking' 'cream' 'crooning' 'day' 'delicious' 'discovery' 'enough'\n",
      " 'ever' 'feed' 'finish' 'first' 'flavor' 'flexible' 'foil' 'for' 'friend'\n",
      " 'from' 'garlic' 'get' 'give' 'go' 'good' 'goood' 'gotten' 'guests' 'ham'\n",
      " 'hands' 'healthy' 'help' 'holiday' 'homes' 'honey' 'hours' 'however' 'if'\n",
      " 'improve' 'in' 'is' 'it' 'its' 'ive' 'jalpenos' 'ketchup' 'last' 'like'\n",
      " 'lots' 'magazine' 'make' 'many' 'maple' 'may' 'me' 'mention' 'minced'\n",
      " 'mine' 'mins' 'mmmm' 'my' 'of' 'off' 'on' 'onions' 'or' 'oven' 'owe'\n",
      " 'part' 'perfect' 'personalized' 'post' 'posting' 'potato' 'quick'\n",
      " 'really' 'recipe' 'recipes' 'result' 'rib' 'sauce' 'serve' 'should'\n",
      " 'simple' 'simply' 'site' 'so' 'some' 'sour' 'still' 'store' 'sugar'\n",
      " 'suit' 'supereasy' 'sweet' 'syrup' 'table' 'taste' 'tastes' 'that' 'the'\n",
      " 'them' 'they' 'this' 'thought' 'throw' 'to' 'tomatoes' 'too' 'up' 'used'\n",
      " 'want' 'what' 'while' 'will' 'with' 'wow' 'wrap' 'you' 'youll' 'your']\n",
      "[[0.19629459 0.         0.         0.19629459 0.         0.\n",
      "  0.         0.         0.         0.39258917 0.         0.\n",
      "  0.         0.         0.         0.19629459 0.         0.\n",
      "  0.         0.19629459 0.19629459 0.         0.         0.19629459\n",
      "  0.19629459 0.         0.         0.         0.15836924 0.\n",
      "  0.         0.         0.         0.15836924 0.         0.\n",
      "  0.19629459 0.19629459 0.15836924 0.         0.19629459 0.\n",
      "  0.19629459 0.19629459 0.         0.         0.19629459 0.\n",
      "  0.19629459 0.19629459 0.         0.         0.19629459 0.19629459\n",
      "  0.19629459 0.         0.         0.         0.         0.\n",
      "  0.         0.19629459 0.         0.         0.         0.\n",
      "  0.         0.         0.19629459 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.40986539 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.40986539 0.         0.         0.40986539 0.         0.\n",
      "  0.         0.40986539 0.         0.         0.33067681 0.\n",
      "  0.         0.         0.         0.         0.33067681 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.33067681\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.1726284  0.         0.         0.1726284\n",
      "  0.         0.1726284  0.51788519 0.         0.1726284  0.\n",
      "  0.         0.1726284  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1726284  0.1726284  0.         0.\n",
      "  0.         0.1726284  0.         0.         0.27855101 0.34525679\n",
      "  0.         0.         0.         0.1726284  0.         0.1726284\n",
      "  0.         0.         0.         0.1726284  0.         0.1726284\n",
      "  0.         0.         0.1392755  0.         0.         0.\n",
      "  0.         0.1392755  0.         0.1726284  0.         0.1726284\n",
      "  0.         0.         0.         0.         0.         0.1392755\n",
      "  0.1726284  0.         0.         0.1726284  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.16061539 0.         0.         0.16061539 0.\n",
      "  0.         0.         0.         0.         0.         0.16061539\n",
      "  0.16061539 0.         0.16061539 0.         0.16061539 0.32123078\n",
      "  0.         0.         0.         0.         0.16061539 0.\n",
      "  0.         0.         0.         0.         0.         0.32123078\n",
      "  0.16061539 0.         0.16061539 0.38875046 0.         0.\n",
      "  0.         0.         0.12958349 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.12958349 0.16061539 0.         0.\n",
      "  0.         0.25916697 0.32123078 0.         0.16061539 0.\n",
      "  0.16061539 0.         0.16061539 0.16061539 0.16061539 0.\n",
      "  0.         0.16061539 0.         0.         0.16061539]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "dfs = df.sample(5)\n",
    "res = dfs['preprocessed_descriptions'].values.tolist()\n",
    "# res\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit_transform(res)\n",
    "vctrzd = vectorizer.fit_transform(res).toarray()\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(vctrzd_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>cranberry glazed ham</th>\n",
       "      <th>chicken quesadilla base</th>\n",
       "      <th>yummy ribs   baked   bbq d   easy</th>\n",
       "      <th>fluffy pan cake</th>\n",
       "      <th>mom s mexican salad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cranberry glazed ham</th>\n",
       "      <td>1</td>\n",
       "      <td>0.077209</td>\n",
       "      <td>0.135101</td>\n",
       "      <td>0.110762</td>\n",
       "      <td>0.082558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chicken quesadilla base</th>\n",
       "      <td>0.077209</td>\n",
       "      <td>1</td>\n",
       "      <td>0.147661</td>\n",
       "      <td>0.019447</td>\n",
       "      <td>0.05438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yummy ribs   baked   bbq d   easy</th>\n",
       "      <td>0.135101</td>\n",
       "      <td>0.147661</td>\n",
       "      <td>1</td>\n",
       "      <td>0.140248</td>\n",
       "      <td>0.233596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fluffy pan cake</th>\n",
       "      <td>0.110762</td>\n",
       "      <td>0.019447</td>\n",
       "      <td>0.140248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mom s mexican salad</th>\n",
       "      <td>0.082558</td>\n",
       "      <td>0.05438</td>\n",
       "      <td>0.233596</td>\n",
       "      <td>0.121484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name                              cranberry glazed ham  \\\n",
       "                                                         \n",
       "cranberry glazed ham                                 1   \n",
       "chicken quesadilla base                       0.077209   \n",
       "yummy ribs   baked   bbq d   easy             0.135101   \n",
       "fluffy pan cake                               0.110762   \n",
       "mom s mexican salad                           0.082558   \n",
       "\n",
       "name                              chicken quesadilla base  \\\n",
       "                                                            \n",
       "cranberry glazed ham                             0.077209   \n",
       "chicken quesadilla base                                 1   \n",
       "yummy ribs   baked   bbq d   easy                0.147661   \n",
       "fluffy pan cake                                  0.019447   \n",
       "mom s mexican salad                               0.05438   \n",
       "\n",
       "name                              yummy ribs   baked   bbq d   easy  \\\n",
       "                                                                      \n",
       "cranberry glazed ham                                       0.135101   \n",
       "chicken quesadilla base                                    0.147661   \n",
       "yummy ribs   baked   bbq d   easy                                 1   \n",
       "fluffy pan cake                                            0.140248   \n",
       "mom s mexican salad                                        0.233596   \n",
       "\n",
       "name                              fluffy pan cake mom s mexican salad  \n",
       "                                                                       \n",
       "cranberry glazed ham                     0.110762            0.082558  \n",
       "chicken quesadilla base                  0.019447             0.05438  \n",
       "yummy ribs   baked   bbq d   easy        0.140248            0.233596  \n",
       "fluffy pan cake                                 1            0.121484  \n",
       "mom s mexican salad                      0.121484                   1  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "df_11 = pd.DataFrame(index = dfs.name, columns = dfs.name)\n",
    "for k,v in enumerate(dfs.name):\n",
    "    for i,j in enumerate(dfs.name):\n",
    "        df_11.at[v,j] = 1 - cosine(vctrzd[k], vctrzd[i])\n",
    "df_11 = df_11.reset_index().rename(columns = {'name':' '})\n",
    "df_11 = df_11.set_index(' ')\n",
    "df_11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>cranberry glazed ham</th>\n",
       "      <th>chicken quesadilla base</th>\n",
       "      <th>yummy ribs   baked   bbq d   easy</th>\n",
       "      <th>fluffy pan cake</th>\n",
       "      <th>mom s mexican salad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cranberry glazed ham</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chicken quesadilla base</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yummy ribs   baked   bbq d   easy</th>\n",
       "      <td>0.135101</td>\n",
       "      <td>0.147661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.140248</td>\n",
       "      <td>0.233596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fluffy pan cake</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mom s mexican salad</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.233596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name                              cranberry glazed ham  \\\n",
       "                                                         \n",
       "cranberry glazed ham                               NaN   \n",
       "chicken quesadilla base                            NaN   \n",
       "yummy ribs   baked   bbq d   easy             0.135101   \n",
       "fluffy pan cake                                    NaN   \n",
       "mom s mexican salad                                NaN   \n",
       "\n",
       "name                              chicken quesadilla base  \\\n",
       "                                                            \n",
       "cranberry glazed ham                                  NaN   \n",
       "chicken quesadilla base                               NaN   \n",
       "yummy ribs   baked   bbq d   easy                0.147661   \n",
       "fluffy pan cake                                       NaN   \n",
       "mom s mexican salad                                   NaN   \n",
       "\n",
       "name                              yummy ribs   baked   bbq d   easy  \\\n",
       "                                                                      \n",
       "cranberry glazed ham                                            NaN   \n",
       "chicken quesadilla base                                         NaN   \n",
       "yummy ribs   baked   bbq d   easy                               NaN   \n",
       "fluffy pan cake                                                 NaN   \n",
       "mom s mexican salad                                        0.233596   \n",
       "\n",
       "name                              fluffy pan cake mom s mexican salad  \n",
       "                                                                       \n",
       "cranberry glazed ham                          NaN                 NaN  \n",
       "chicken quesadilla base                       NaN                 NaN  \n",
       "yummy ribs   baked   bbq d   easy        0.140248            0.233596  \n",
       "fluffy pan cake                               NaN                 NaN  \n",
       "mom s mexican salad                           NaN                 NaN  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = df_11[df_11 != 1].max().values # массив с самыми большими результатами(не равными 1)\n",
    "df_11[df_11 == val] #датафрейм, содержащий только самые большие результаты(не равные 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
